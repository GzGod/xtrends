import { NextRequest } from "next/server";

export const runtime = "nodejs";
export const dynamic = "force-dynamic";

interface TweetSummary {
  rank: number;
  author: string;
  content: string;
  views: string;
  likes: string;
  heatScore: number;
  tags: string[];
}

interface RequestBody {
  tweets: TweetSummary[];
  domainTags: { name: string; count: number }[];
  hotTags: { name: string; count: number }[];
  group: string;
  hours: number;
}

function buildPrompt(body: RequestBody): string {
  const { tweets, domainTags, hotTags, group, hours } = body;

  const groupLabel = group === "cn" ? "ä¸­æ–‡æ¨ç‰¹åœˆ" : group === "en" ? "è‹±æ–‡æ¨ç‰¹åœˆ" : "å…¨çƒæ¨ç‰¹";
  const top20 = tweets.slice(0, 20);

  const tweetLines = top20
    .map(
      (t, i) =>
        `${i + 1}. [çƒ­åº¦${t.heatScore.toFixed(0)}|${t.views}æµè§ˆ] ${t.content}ï¼ˆ@${t.author}ï¼‰`
    )
    .join("\n");

  const domainStr = domainTags.map((t) => `${t.name}(${t.count}æ¡)`).join("ã€");
  const hotStr = hotTags
    .slice(0, 8)
    .map((t) => `#${t.name}(${t.count})`)
    .join(" ");

  return `ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç¤¾äº¤åª’ä½“å†…å®¹ç­–ç•¥å¸ˆï¼Œæ“…é•¿åˆ†ææ¨ç‰¹çƒ­ç‚¹å¹¶ç»™å‡ºå†™ä½œå»ºè®®ã€‚

å½“å‰æ•°æ®ï¼š${groupLabel}ï¼Œè¿‡å» ${hours} å°æ—¶çƒ­é—¨æ¨æ–‡ TOP 20ï¼š

${tweetLines}

é¢†åŸŸåˆ†å¸ƒï¼š${domainStr}
çƒ­é—¨è¯é¢˜æ ‡ç­¾ï¼š${hotStr}

è¯·åŸºäºä»¥ä¸Šæ•°æ®ï¼Œç»™å‡ºä¸€ä»½ç®€æ´å®ç”¨çš„å†™ä½œå»ºè®®æŠ¥å‘Šï¼ŒåŒ…å«ä»¥ä¸‹å››ä¸ªéƒ¨åˆ†ï¼š

## ğŸ”¥ å½“å‰æœ€çƒ­é€‰é¢˜æ–¹å‘ï¼ˆ3ä¸ªï¼‰
åˆ—å‡º3ä¸ªæœ€å€¼å¾—å†™çš„é€‰é¢˜æ–¹å‘ï¼Œæ¯ä¸ªè¯´æ˜ä¸ºä»€ä¹ˆçƒ­ã€é€‚åˆä»€ä¹ˆè§’åº¦åˆ‡å…¥ã€‚

## ğŸ“ å†…å®¹åˆ›ä½œå»ºè®®ï¼ˆ3æ¡ï¼‰
é’ˆå¯¹å½“å‰çƒ­ç‚¹ï¼Œç»™å‡ºå…·ä½“çš„å†…å®¹åˆ›ä½œç­–ç•¥å»ºè®®ã€‚

## ğŸ’¡ æ¨èæ ‡é¢˜ç¤ºä¾‹ï¼ˆ5ä¸ªï¼‰
ç»™å‡º5ä¸ªå¯ä»¥ç›´æ¥ç”¨æˆ–å‚è€ƒçš„æ¨æ–‡/æ–‡ç« æ ‡é¢˜ï¼Œè¦æœ‰å¸å¼•åŠ›ã€ç¬¦åˆå½“å‰çƒ­ç‚¹ã€‚

## âš¡ å¿«é€Ÿè¡ŒåŠ¨å»ºè®®
1-2å¥è¯ï¼Œå‘Šè¯‰åˆ›ä½œè€…ç°åœ¨æœ€åº”è¯¥åšä»€ä¹ˆã€‚

è¦æ±‚ï¼šè¯­è¨€ç®€æ´æœ‰åŠ›ï¼Œé¿å…åºŸè¯ï¼Œæ¯æ¡å»ºè®®è¦å…·ä½“å¯æ‰§è¡Œã€‚`;
}

export async function POST(req: NextRequest) {
  const apiKey = process.env.AI_API_KEY;
  const apiBase = process.env.AI_API_BASE || "https://max.openai365.top/v1";
  const model = process.env.AI_MODEL || "claude-3-7-sonnet";

  if (!apiKey) {
    return new Response(
      JSON.stringify({ error: "AI_API_KEY not configured" }),
      { status: 500, headers: { "Content-Type": "application/json" } }
    );
  }

  let body: RequestBody;
  try {
    body = await req.json();
  } catch {
    return new Response(JSON.stringify({ error: "Invalid JSON" }), {
      status: 400,
      headers: { "Content-Type": "application/json" },
    });
  }

  const prompt = buildPrompt(body);

  // Stream response from AI
  const aiRes = await fetch(`${apiBase}/chat/completions`, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: `Bearer ${apiKey}`,
    },
    body: JSON.stringify({
      model,
      messages: [{ role: "user", content: prompt }],
      stream: true,
      max_tokens: 1200,
      temperature: 0.7,
    }),
    signal: AbortSignal.timeout(60000),
  });

  if (!aiRes.ok) {
    const err = await aiRes.text();
    return new Response(JSON.stringify({ error: err }), {
      status: 502,
      headers: { "Content-Type": "application/json" },
    });
  }

  // Pipe the SSE stream directly to client
  return new Response(aiRes.body, {
    headers: {
      "Content-Type": "text/event-stream",
      "Cache-Control": "no-cache",
      Connection: "keep-alive",
    },
  });
}
